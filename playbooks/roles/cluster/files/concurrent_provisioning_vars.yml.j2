openshift_disable_check: disk_availability,docker_storage,memory_availability,package_version,docker_image_availability
ansible_ssh_user: root
deployment_type: openshift-enterprise
openshift_deployment_type: 'openshift-enterprise'
openshift_master_api_port: 443
openshift_master_console_port: 443
osm_default_node_selector: 'type=compute'
openshift_docker_options: '--log-driver=json-file --log-opt max-size=50m'

openshift_release: "3.11"
openshift_image_tag: "v3.11.154"

rhsub_pool: {{ rh_pool }}

domain: {{ domain }}
oreg_auth_user: {{ rh_user }}
oreg_auth_password: {{ rh_pass }}

# cluster_id is deprecated in favor of openshift_clusterid
openshift_clusterid: {{ oo_clusterid }}
openshift_master_cluster_hostname: api.{{ oo_clusterid }}.{{ domain }}
openshift_master_cluster_public_hostname: {{ oo_clusterid }}.{{ domain }}
openshift_master_public_api_url: https://{{ oo_clusterid }}.{{ domain }}
openshift_master_public_console_url: https://{{ oo_clusterid }}.{{ domain }}/console

# TODO
os_sdn_network_plugin_name: redhat/openshift-ovs-networkpolicy

openshift_master_dynamic_provisioning_enabled: true

osm_custom_cors_origins:
- console.{{ oo_clusterid }}.{{ domain }}
- api.{{ oo_clusterid }}.{{ domain }}

openshift_cloudprovider_kind: aws
openshift_cloudprovider_aws_access_key: {{ aws_access_key }}
openshift_cloudprovider_aws_secret_key: {{ aws_secret_key }}

aws_access_key: {{ aws_access_key }}
aws_secret_key: {{ aws_secret_key }}

AWS_SECRET_ACCESS_KEY: "{{ aws_secret_key }}"
AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"

openshift_master_identity_providers:
- name: my_htpasswd_provider 
  challenge: true 
  login: true 
  mappingMethod: claim 
  kind: HTPasswdPasswordIdentityProvider

openshift_master_manage_htpasswd: true

openshift_master_htpasswd_users: {'{{ htpasswd_username}}': '{{ htpasswd_password }}'}

openshift_master_named_certificates:
- keyfile: {{ scf_retval_openshift_key }}
  certfile: {{ scf_retval_openshift_cert }}
  names:
  - {{ oo_clusterid }}.{{ domain }}

openshift_install_examples: True

openshift_master_oauth_always_show_provider_selection: False

# os_firewall_use_firewalld: false
#osm_cluster_network_cidr:

# StorageClass Parameters

# Openshift Router
openshift_hosted_manage_router: true
openshift_hosted_router_selector: 'type=infra'
openshift_hosted_router_replicas: 3

# openshift_hosted_routers
openshift_hosted_routers: [{"name": "router", "certificate": {"keyfile": "/tmp/{{ oo_clusterid }}/certs/wildcard.apps.{{ oo_clusterid }}.{{ domain }}.key", "certfile": "/tmp/{{ oo_clusterid }}/certs/wildcard.apps.{{ oo_clusterid }}.{{ domain }}.crt", "cafile": "/tmp/{{ oo_clusterid }}/certs/rootCA.pem"}, "replicas": 3, "serviceaccount": "router", "namespace": "default", "stats_port": 1936, "edits": [{"action": "update", "value": {"name": "ROUTER_USE_PROXY_PROTOCOL", "value": "true"}, "key": "spec.template.spec.containers[0].env"}], "selector": "type=infra", "ports": ["80:80", "443:443"]}]


# Openshift Registry Console
# We always install it, this lets us change where it pulls its image from
osm_use_cockpit: false

# Openshift Web Console
openshift_web_console_install: true

# Openshift Ansible Service Broker
openshift_ansible_service_broker_install: true

# Openshift Openshift Service Catalog
openshift_enable_service_catalog: true
openshift_service_catalog_image: "registry.redhat.io/openshift3/ose-service-catalog:v3.11.69"

# Openshift Template Service Broker
openshift_template_service_broker_install: true
template_service_broker_selector:
  type: infra

# Openshift Prometheus
openshift_cluster_monitoring_operator_install: true
# FIXME this var is deprecated in favor of openshift_cluster_monitoring_operator_install
#openshift_hosted_prometheus_deploy: true

# Not sure if this is needed
# Openshift Management (CloudForms)
openshift_management_install_management: false

# Openshift Logging
openshift_logging_install_logging: {{ flag_provision_logging }}
logging_elasticsearch_cluster_size: 3
openshift_logging_image_version: v3.11

openshift_logging_kibana_env_vars:
  ELASTICSEARCH_REQUESTTIMEOUT: 600000
openshift_logging_kibana_nodeselector:
  type: infra

openshift_logging_curator_memory_limit: 512Mi
openshift_logging_kibana_memory_limit: 1Gi
openshift_logging_curator_nodeselector:
  type: infra
openshift_logging_es_number_of_shards: 1
openshift_logging_curator_default_days: 14
openshift_logging_use_ops: False
openshift_logging_curator_script_log_level: INFO
openshift_logging_fluentd_cpu_request: 100m
openshift_logging_es_cluster_size: 3
openshift_logging_kibana_proxy_memory_limit: 256Mi
openshift_logging_es_pvc_dynamic: True
openshift_logging_es_number_of_replicas: 1
openshift_logging_es_pvc_size: 500Gi
openshift_logging_elasticsearch_kibana_index_mode: shared_ops
openshift_logging_fluentd_nodeselector:
  logging-infra-fluentd: "true"
openshift_logging_kibana_cpu_request: 25m
openshift_logging_kibana_replica_count: 1
openshift_logging_fluentd_hosts: []
openshift_logging_kibana_proxy_cpu_request: 25m
openshift_logging_fluentd_memory_limit: 512Mi
openshift_logging_curator_log_level: WARN
openshift_logging_es_memory_limit: 12Gi
openshift_logging_es_cpu_request: 375m
openshift_logging_curator_cpu_request: 25m
openshift_logging_es_nodeselector:
  type: infra
openshift_logging_elasticsearch_proxy_memory_limit: 256Mi


# Openshift Metrics
openshift_metrics_cassandra_storage_type: dynamic
#openshift_metrics_hawkular_hostname: metrics.{{ oo_clusterid }}.{{ domain }}
openshift_metrics_install_metrics: {{ flag_provision_metrics }}
openshift_metrics_start_cluster: 'true'
openshift_metrics_startup_timeout: 500
openshift_metrics_hawkular_limits_memory: 3Gi
openshift_metrics_heapster_limits_memory: 3.75Gi
openshift_metrics_resolution: 30s
openshift_metrics_project: openshift-infra
openshift_metrics_hawkular_nodeselector:
  type: infra
openshift_metrics_heapster_requests_memory: 3.75Gi
openshift_metrics_cassandra_limits_memory: 4Gi
openshift_metrics_cassandra_replicas: 3
openshift_metrics_heapster_standalone: False
openshift_metrics_hawkular_requests_memory: 3Gi
openshift_metrics_heapster_requests_cpu: 100m
openshift_metrics_duration: 7
openshift_metrics_cassandra_requests_cpu: 375m
openshift_metrics_cassandra_requests_memory: 4Gi
openshift_metrics_cassandra_nodeselector:
  type: infra
openshift_metrics_hawkular_requests_cpu: 100m
openshift_metrics_heapster_nodeselector:
  type: infra
openshift_metrics_cassandra_pvc_size: 100Gi
openshift_metrics_hawkular_replicas: 1

# ------------------------ #
# Common/Cluster Variables #
# ------------------------ #

# specify a clusterid
# This value is also used as the default value for many other components.
openshift_aws_clusterid: "{{ oo_clusterid }}"

# AWS region
# This value will instruct the plays where all items should be created.
# Multi-region deployments are not supported using these plays at this time.
openshift_aws_region: "{{ oo_sublocation }}"

openshift_aws_create_iam_role: true

openshift_aws_create_dns: true
openshift_aws_custom_dns_provider_role: "{{ g_play_dns_role_path }}"
openshift_aws_dns_provider: "custom"
openshift_aws_dns_zone: "{{ domain }}"

openshift_master_bootstrap_auto_approve: true

openshift_master_default_subdomain: apps.{{ oo_clusterid }}.{{ domain }}

# --- #
# VPC #
# --- #

# openshift_aws_create_vpc defaults to true.  If you don't wish to provision
# a vpc, set this to false.
#openshift_aws_create_vpc: true

# openshift_aws_vpc
# Thi creates the "openshift_aws_vpc" variable
openshift_aws_vpc: {"subnets": {"{{ oo_sublocation }}": [{"cidr": "172.31.0.0/21", "az": "{{ oo_sublocation }}a"}]}, "cidr": "172.31.0.0/16", "name": "{{ oo_clusterid }}"}

# Name of the vpc.  Needs to be set if using a pre-existing vpc.
#openshift_aws_vpc_name: "{{ oo_clusterid }}"

# Name of the subnet in the vpc to use.  Needs to be set if using a pre-existing
# vpc + subnet. Otherwise will use the subnet with 'default_az' set (see above
# example VPC structure)
#openshift_aws_subnet_az:

# -------------- #
# Security Group #
# -------------- #

# openshift_aws_create_security_groups defaults to true.  If you wish to use
# an existing security group, set this to false.
openshift_aws_create_security_groups: true

# openshift_aws_build_ami_group is the name of the security group to build the
# ami in.  This defaults to the value of openshift_aws_clusterid.
#openshift_aws_build_ami_group: "{{ oo_clusterid }}"

openshift_aws_base_ami: "ami-changme"

# openshift_aws_launch_config_security_groups specifies the security groups to
# apply to the launch config.  The launch config security groups will be what
# the cluster actually is deployed in.
#openshift_aws_launch_config_security_groups: see roles/openshift_aws/defaults.yml

# openshift_aws_node_security_groups are created when
# openshift_aws_create_security_groups is set to true.
#openshift_aws_node_security_groups: see roles/openshift_aws/defaults.yml

# -------- #
# ssh keys #
# -------- #

# Specify the key pair name here to connect to the provisioned instances.  This
# can be an existing key, or it can be one of the keys specified in
# openshift_aws_users
openshift_aws_ssh_key_name: towerProvisioner_key

# -- #
# S3 #
# -- #

# Create an s3 bucket.
#openshift_aws_create_s3: True

openshift_aws_s3_bucket_name: {{ oo_clusterid }}-3scale

# --- #
# ELB #
# --- #


# custom certificates are required for the ELB
openshift_aws_iam_cert_name: {{ oo_clusterid }}

# todo certs
openshift_aws_iam_cert_path: "{{ scf_retval_openshift_cert }}"
openshift_aws_iam_cert_chain_path: "{{ scf_retval_chain_cert }}"
openshift_aws_iam_cert_key_path: "{{ scf_retval_openshift_key }}" 

# oa_* vars are vars that we create so we don't have to copy everything around
oa_default_openshift_node_group_edits:
- key: kubeletArguments.system-reserved
  value:
  - 'cpu=1000m,memory=1Gi'
- key: kubeletArguments.image-gc-high-threshold
  value:
  - '80'
- key: kubeletArguments.image-gc-low-threshold
  value:
  - '60'
- key: kubeletArguments.maximum-dead-containers
  value:
  - '50'
- key: kubeletArguments.maximum-dead-containers-per-container
  value:
  - '2'
- key: kubeletArguments.minimum-container-ttl-duration
  value:
  - 5m

openshift_node_groups:
- name: node-config-master
  labels:
  - 'node-role.kubernetes.io/master=true'
  - 'type=master'
  - "region={{ oo_sublocation }}"
  - 'logging-infra-fluentd=true'
  edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"
- name: node-config-infra
  labels:
  - 'node-role.kubernetes.io/infra=true'
  - 'type=infra'
  - "region={{ oo_sublocation }}"
  - 'logging-infra-fluentd=true'
  - 'config_pod=true'
  edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"
- name: node-config-compute
  labels:
  - 'node-role.kubernetes.io/compute=true'
  - 'type=compute'
  - "region={{ oo_sublocation }}"
  - 'logging-infra-fluentd=true'
  - 'config_pod=true'
  edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"

openshift_aws_node_groups:
- name: "{{ oo_clusterid }} Compute"
  group: compute
  node_group_config: node-config-compute
  tags:
    host-type: node
    sub-host-type: compute
    runtime: docker
    scalegroup: 'True'
    config: 'False'
- name: "{{ oo_clusterid }} Infra"
  group: infra
  node_group_config: node-config-infra
  tags:
    host-type: node
    sub-host-type: infra
    runtime: docker
    scalegroup: 'True'
    config: 'False'

openshift_aws_master_instance_config:
  instance_type: {{ master_instance_size }}
  volumes: "{{ '{{' }} openshift_aws_master_volumes {{ '}}' }}"
  health_check: "{{ '{{' }} openshift_aws_scale_group_health_check {{ '}}' }}"
  exact_count: {{ openshift_aws_master_group_desired_size | default(3) }}
  termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
  iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['master'].name {{ '}}' }}"
  elbs: "{{ '{{' }} openshift_aws_elb_dict | json_query('master.[*][0][*].name') {{ '}}' }}"
  groups:
  - "{{ oo_clusterid }}"  # default sg
  - "{{ oo_clusterid }}_master"  # node type sg
  - "{{ oo_clusterid }}_master_k8s"  # node type sg k8s

openshift_aws_master_volumes:
- device_name: /dev/sda1
  volume_size: 100
  volume_type: gp2
  delete_on_termination: False
- device_name: /dev/sdb
  volume_size: 200
  volume_type: gp2
  delete_on_termination: False

# This is default, but added the "config" tag to enable config loop
openshift_aws_master_group:
- name: "{{ oo_clusterid }} master group"
  group: master
  node_group_config: node-config-master
  tags:
    host-type: master
    sub-host-type: default
    runtime: docker
    config: "{{ '{{' }} 'False' | string {{ '}}' }}"

openshift_aws_node_group_config:
  compute:
    instance_type: {{ compute_instance_size }}
    volumes: "{{ '{{' }} openshift_aws_node_group_config_node_volumes {{ '}}' }}"
    health_check:
      period: 60
      type: EC2
    min_size: 2
    max_size: {{ openshift_aws_compute_group_desired_size|int * 3 }}
    desired_size: {{ openshift_aws_compute_group_desired_size }}
    termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
    replace_all_instances: "{{ '{{' }} openshift_aws_node_group_replace_all_instances {{ '}}' }}"
    iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['compute'].name {{ '}}' }}"
  infra:
    instance_type: {{ infra_instance_size }}
    volumes: "{{ '{{' }} openshift_aws_node_group_config_node_volumes {{ '}}' }}"
    health_check:
      period: 60
      type: EC2
    min_size: 2
    max_size: {{ openshift_aws_infra_group_desired_size|int * 3 }}
    desired_size: {{ openshift_aws_infra_group_desired_size }}
    termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
    replace_all_instances: "{{ '{{' }} openshift_aws_node_group_replace_all_instances {{ '}}' }}"
    iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['infra'].name {{ '}}' }}"
    elbs: "{{ '{{' }} openshift_aws_elb_dict | json_query('infra.[*][0][*].name') {{ '}}' }}"

openshift_aws_node_group_config_node_volumes:
- device_name: /dev/sda1
  volume_size: 100
  device_type: gp2
  delete_on_termination: True
- device_name: /dev/sdb
  volume_size: 200
  device_type: gp2
  delete_on_termination: True

openshift_aws_launch_config_security_groups:
  master:
  - "{{ oo_clusterid }}"  # default sg
  - "{{ oo_clusterid }}_master"  # node type sg
  - "{{ oo_clusterid }}_master_k8s"  # node type sg k8s
  compute:
  - "{{ oo_clusterid }}"  # default sg
  - "{{ oo_clusterid }}_compute"  # node type sg
  - "{{ oo_clusterid }}_compute_k8s"  # node type sg k8s
  infra:
  - "{{ oo_clusterid }}"  # default sg
  - "{{ oo_clusterid }}_infra"  # node type sg
  - "{{ oo_clusterid }}_infra_k8s"  # node type sg k8s
  compute-crio:
  - "{{ oo_clusterid }}"  # default sg
  - "{{ oo_clusterid }}_compute"  # node type sg
  - "{{ oo_clusterid }}_compute_k8s"  # node type sg k8s

openshift_aws_ami: {{ g_play_image_id }}

openshift_aws_ami_map:
  master: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"
  infra: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"
  compute: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"

openshift_aws_node_user_data: |
  {{ '{%' }} if l_instance_tags['host-type'] == 'master' {{ '%}' }}
  #cloud-config
  write_files:
  - path: /root/openshift_bootstrap/openshift_settings.yaml
    owner: 'root:root'
    permissions: '0640'
    content: |
      openshift_node_config_name: node-config-master

  runcmd:
  - [ ansible-playbook, /root/openshift_bootstrap/bootstrap.yml]
  {{ '{%' }}  else {{ '%}' }}
  #cloud-config
  write_files:
  - path: /root/openshift_bootstrap/openshift_settings.yaml
    owner: 'root:root'
    permissions: '0640'
    content: |
      openshift_node_config_name: "{{ '{{' }} openshift_aws_node_group.node_group_config {{ '}}' }}"
  - path: /etc/origin/node/bootstrap.kubeconfig
    owner: 'root:root'
    permissions: '0640'
    encoding: b64
    content: "{{ '{{' }} openshift_aws_launch_config_bootstrap_token | b64encode {{ '}}' }}"

  runcmd:
  - [ ansible-playbook, /root/openshift_bootstrap/bootstrap.yml]
  - [ systemctl, restart, systemd-hostnamed]
  - [ systemctl, restart, NetworkManager]
  - [ systemctl, enable, atomic-openshift-node]
  - [ systemctl, start, atomic-openshift-node]
  {{ '{%' }} if 'infra' in openshift_aws_node_group.node_group_config {{ '%}' }}
  - [ /root/sre_firstboot_scripts/infra-elasticsearch-sysctl.sh]
  {{ '{%' }}  endif {{ '%}' }}
  {{ '{%' }}  endif {{ '%}' }}
